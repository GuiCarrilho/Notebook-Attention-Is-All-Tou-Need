{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOctyMKNt+j8NJ0Ny8oq+pz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rWcn4cUyiXLR"},"outputs":[],"source":["#make the data augmentation\n","import numpy as np\n","import pandas as pd\n","import sklearn\n","from tqdm.notebook import tqdm\n","\n","# from nlpaug.util.file.download import DownloadUtil\n","# DownloadUtil.download_fasttext(model_name='wiki-news-300d-1M', dest_dir='.') # Download fasttext model\n","#DownloadUtil.download_word2vec(dest_dir='.') # Download word2vec model\n","\n","df = pd.read_csv('fixed.csv')\n","\n","#transform the labels in numbers\n","int2label = {}\n","\n","for i, disease in enumerate(df['label'].unique()):\n","    int2label[i] = disease\n","\n","label2int = {v : k for k, v in int2label.items()}\n","num_classes = len(int2label)\n","\n","#transform all the labels in integers\n","df['label'] = df['label'].map(lambda x : label2int[x])\n","\n","#separate train and validation data for augmentation\n","from sklearn.model_selection import train_test_split\n","\n","train,valid=train_test_split(df,test_size=0.15)\n","print('Shape of train before augmentation: ',train.shape)\n","print('Shape of Validation: ', valid.shape)\n","\n","valid.to_csv(\"validation-data.csv\", sep=',', encoding='utf-8', index=False)\n","\n","\n","\n","import nlpaug.augmenter.char as nac\n","import nlpaug.augmenter.word as naw\n","import nlpaug.augmenter.sentence as nas\n","import nlpaug.flow as nafc\n","from sklearn.utils import shuffle\n","from tqdm import tqdm\n","from nlpaug.util import Action\n","\n","#this functions receive the dataset, the label and a number of samples (default is 300)\n","#make the data augmentation\n","import random\n","import nlpaug.augmenter.char as nac\n","import nlpaug.augmenter.word as naw\n","import nlpaug.augmenter.sentence as nas\n","import nlpaug.flow as nafc\n","from sklearn.utils import shuffle\n","from tqdm import tqdm\n","from nlpaug.util import Action\n","\n","#this functions receive the dataset, the label and a number of samples (default is 300)\n","def augment_text(df,label,samples=300):\n","\n","  #create the model for augmentation\n","  #here we use word2vec\n","  #the model is used for word substitution, selecting some random words and substiting to similar words\n","  aug = naw.RandomWordAug(action=\"swap\")\n","\n","  #array of texts and labels\n","  new_texts = []\n","  labels = []\n","\n","  #separate the current label for augmentation\n","  df_n = df[df.label==label].reset_index(drop=True)\n","  print('Original shape of class',df_n.shape)\n","\n","  #for each row in the original dataset, and for all samples given, make the augmentation\n","  for i in tqdm(np.random.randint(0,len(df_n),samples)):\n","    #locate the current row in the dataset, and separate label and symptom\n","    symptom = df_n.iloc[i]['text']\n","    labels.append(df.iloc[i]['label'])\n","\n","    #make the augmentation and add to the array\n","    augmented_text_data = aug.augment(symptom)\n","\n","    new_texts.append(augmented_text_data)\n","\n","  #create a new dataframe with the text generated and concat to the original, then make a shuffle\n","  new = pd.DataFrame({'text':new_texts,'label':labels})\n","  df_new = shuffle(pd.concat([df_n,new]).reset_index(drop=True))\n","  print('Augmented shape of class',df_new.shape)\n","  return df_new\n","\n","#create a list of dataframes\n","data_frames = []\n","#for each class, make the augmentation\n","for i in range(0,1):\n","  print('augmenting class ',i,\"/23\")\n","  data_frames.append(augment_text(train, i, 1))\n","\n","train_augmented = pd.concat(data_frames)\n","\n","\n","#create a list of dataframes\n","data_frames = []\n","#for each class, make the augmentation\n","for i in range(0,24):\n","  print('augmenting class ',i,\"/23\")\n","  data_frames.append(augment_text(train, i, 200))\n","\n","train_augmented = pd.concat(data_frames)\n","train_augmented.to_csv(\"agumented-test-data.csv\", sep=',', encoding='utf-8', index=False)"]}]}